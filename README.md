Unraveling mysteries hidden within datasets, a relentless data detective, transforming chaos into knowledge.

- üëã Hi, I‚Äôm @TatjanaChernenko
- üëÄ I‚Äôm interested in Data Science, ML/DL, NLP and .
- üì´ How to reach me: tatjana.chernenko.work@gmail.com
- üìÅ New Public Repository: This new public GitHub profile contains both old (starting from approx. 2015) and new my projects, uploaded now after years of working in a private capacity due to privacy policies of my employers. 
- üìÅ Project Uploads: All projects uploaded here are from my personal endeavors and university research. Due to privacy policies at SAP SE, where I am employed, I am unable to share work-related projects publicly. These repositories exclusively feature my private projects and are newly uploaded to this fresh GitHub profile. Thank you for your understanding.

# My Projects

## Research Repositories
### NLP / ML
- 2017/2018 [CHERTOY: Word Sense Induction for better web search result clustering](https://github.com/TatjanaChernenko/word_sense_induction_CHERTOY_system/tree/main) - An approach to improve **word sense induction systems (WSI)** for web search result clustering. Exploring the boundaries of vector space models for the WSI Task. CHERTOY system. Authors: Tatjana Chernenko, Utaemon Toyota.

Whitepaper - [link](https://github.com/TatjanaChernenko/word_sense_induction_CHERTOY_system/blob/main/Results.pdf)
  
*Key words: word sense induction, web search results clustering, ML, NLP, word2vec, sent2vec, NLP, data science, data processing.*

- 2018 [Data-to-text: Natural Language Generation from structured inputs](https://github.com/TatjanaChernenko/image_description_generation) - This project investigates the **generation of descriptions of images** focusing on spatial relationships between the objects and sufficient attributes for the objects. Leveraging an encoder-decoder architecture with LSTM cells (the Dong et al. (2017) is taken as basis), the system transforms normalized vector representations of attributes into fixed-length vectors. These vectors serve as initial states for a decoder generating target sentences from sequences in description sentences.

Whitepaper - [link](https://github.com/TatjanaChernenko/image_description_generation/blob/main/docs/Paper_NL_generation.pdf)

*Key words: natural language generation, encoder-decoder, ML, NLP, data science, feed-forward neural network, LSTMs.*

- 2018 [Text Summarization research: Optimizing LexRank system with ECNU features](https://github.com/TatjanaChernenko/text_summarization_LexRank_modified_ecnu) -  enhancing the LexRank-based **text summarization** system by incorporating semantic similarity measures from the ECNU system. The LexRank-based text summarization system employs a stochastic graph-based method to compute the relative importance of textual units for extractive multi-document text summarization. This implementation initially utilizes cosine similarity between sentences as a key metric. In this model, a connectivity matrix based on intra-sentence cosine similarity is used as the adjacency matrix of the graph representation of sentences. The objective is to explore the impact of replacing cosine similarity with a combination of features from the ECNU system, known for its semantic similarity measure. This modification aims to improve the summarization effectiveness of the LexRank approach.

Whitepaper - [link](https://github.com/TatjanaChernenko/text_summarization_LexRank_modified_ecnu/blob/main)

*Key words: natural language processing, text summarizaton, ML, NLP, data science, LexRank, ECNU, semantic similarity metrics, multi-document text summarization, cosine similarity, connectivity matrix, optimization.*

- 2019, [Reinforcement Learning agent for Bomberman game](https://github.com/TatjanaChernenko/reinforcement_learning_agent_Bomberman_game) Training a **RL agent** for the multi-player game Bomberman using reinforcement learning, deep Q-learning with a dueling network architecture and separate decision and target networks, prioritized experience replay.

Whitepaper - [link](https://github.com/TatjanaChernenko/reinforcement_learning_agent_Bomberman_game/blob/main/Report.pdf)

*Key words: reinforcement learning, q-learning.*

- 2018, [Speech-to-text: Transfer Learning for Automatic Speech Translation (playground)](https://github.com/TatjanaChernenko/automatic_speech_translation_transfer_learning) - Playground for the **Automated Speech Translation (AST)** with transfer learning vs. AST trained from scratch; hyperparameters tuning and evaluation.

Report - [link](https://github.com/TatjanaChernenko/automatic_speech_translation_transfer_learning/blob/main/AST_Transfer_Learning_report.pdf)

*Key words: transfer learning, automated speech translation*

- 2018, [Data Augmentation techniques for binary- and multi-label classification](https://github.com/TatjanaChernenko/data_augmentation) - Exploring **Data Augmentation techniques** (Thesaurus and Backtranslation, a winning Kaggle technique) to expand existing datasets, evaluating on binary- and multi-label classification task (spam/not spam and news articles classification). Important when training data is limited, especially in Machine Learning (ML) or Deep Learning (DL) applications. The primary concept involves altering text while retaining its meaning to enhance the dataset's diversity.

*Key words: data augmentation, data science, ML, DL, binary and multi-class classification*

- Collection of **chatbots, dialogue systems**

(*coming soon*)

# Playground

## EDA (Explorative Data Analysis)
- [Explorative Data Analysis of Aibnb rental prices in New York, 2019](https://github.com/TatjanaChernenko/ml_playground/blob/main/Explorative%20Data%20Analysis%20-%20AirBnb%20Prices%20in%20New%20York.ipynb) - Jupyter Notebook

(*further projects coming soon*)

## Sentiment Analysis

(*coming soon*)

## Voice technologies (speech-to-text, speech-to-speech, text-to-speech)
Forks:
- [Speech-to-Text-WaveNet](https://github.com/TatjanaChernenko/speech-to-text-wavenet): End-to-end sentence level English speech recognition based on DeepMind's WaveNet and tensorflow (forked from buriburisuri)
- [Speech-to-text via Whisper and GPT-4](https://github.com/TatjanaChernenko/speech_to_text_with_whisper_to_GPT) - transcribe dictations to text using whisper, and then fixing the resulting transcriptions into usable text using gpt-4 (forked from MNoichl)
- [TensorFlow Speech Recognition](https://github.com/TatjanaChernenko/AUDIO-PREOCESSING-AND-SPEECH-CLASSIFICATION) - audio processing and speech classification with Tensorflow - convolution neural networks (forked from harshel)

(*further projects coming soon*)

## Various ML tasks

- https://github.com/TatjanaChernenko/ml_playground
- [Regression Task: Predicting Airbnb rental prices in New York](https://github.com/TatjanaChernenko/ml_playground/blob/main/Explorative%20Data%20Analysis%20-%20AirBnb%20Prices%20in%20New%20York.ipynb) - **Regression task** to predict rental prices in New York, playground. Models used: Linear Regression, Decision Trees, NNs.

(*coming soon*)

## Apps with ChatGPT and OpenAI
- [OpenAI basic app](https://github.com/TatjanaChernenko/open_ai_basic_app) - updating the basic **OpenAI simple app** to generate pet names to correspond to the OpenAI changes in code (January, 2024)

(*coming soon*)

## NMT

(*coming soon*)

# Inspiration

## [OpenAI](https://github.com/openai)
- [OpenAI - simple app](https://github.com/openai/openai-quickstart-python) - My note: a model used and several functions are already deprecated; my version above has things updated.
- [Retrieval-Augmented Generation in Azure using Azure AI search](https://github.com/Azure-Samples/azure-search-openai-demo) - A sample app for the Retrieval-Augmented Generation pattern running in Azure, using Azure AI Search for retrieval and Azure OpenAI large language models to power ChatGPT-style and Q&A experiences.
- [A collection of custom OpenAI WebApps](https://github.com/MaxineXiong/OpenAI-API-Web-Apps)
- [Real time speech2text](https://github.com/saharmor/whisper-playground) - Build real time speech2text web apps using OpenAI's Whisper
- [OpenAI cookbook](https://github.com/openai/openai-cookbook)
- [OpenAI WhatsApp Chatbot](https://github.com/simonsanvil/openai-whatsapp-chatbot)
- [GPT-engineer](https://github.com/gpt-engineer-org/gpt-engineer) - Specify what you want it to build, the AI asks for clarification, and then builds it.
- [Prompt-engineering Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
- [PDF search app with OpenAI](https://github.com/alejandro-ao/langchain-ask-pdf) - an AI-app that allows you to upload a PDF and ask questions about it. It uses OpenAI's LLMs to generate a response.
- [OpenAI Code Automation](https://github.com/nanowell/OpenAI-GPT-Code-Automation) - Fully coded Apps by GPT-4 and ChatGPT. Power of AI coding automation and new way of developing.
- [Semantic Search](https://github.com/nomic-ai/semantic-search-app-template) - Tutorial and template for a semantic search app powered by the Atlas Embedding Database, Langchain, OpenAI and FastAPI

## [Microsoft](https://github.com/microsoft)
- [OptiGuide](https://github.com/microsoft/OptiGuide) - Large Language Models for Supply Chain Optimization
- [Generative AI lessons](https://github.com/microsoft/generative-ai-for-beginners) - 12 Lessons, Get Started Building with Generative AI
- [LLMOps Workshop](https://github.com/microsoft/llmops-workshop) - Learn how to build solutions with Large Language Models.
- [Data Science Lessons](https://github.com/microsoft/Data-Science-For-Beginners)
- [AI Lessons](https://github.com/microsoft/AI-For-Beginners)
- [unilm](https://github.com/microsoft/unilm) - Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities. An open source AutoML toolkit for automate machine learning lifecycle, including feature engineering, neural architecture search, model compression and hyper-parameter tuning.
- [Old Photo Restoration via Deep Latent Space Translation](https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life) - Bringing Old Photo Back to Life (CVPR 2020 oral)
- [NNI](https://github.com/microsoft/nni) - An open source AutoML toolkit for automate machine learning lifecycle, including feature engineering, neural architecture search, model compression and hyper-parameter tuning.
  
## [Meta Research](https://github.com/facebookresearch)

- [From Audio to Photoreal Embodiment](https://github.com/facebookresearch/audio2photoreal): Synthesizing Humans in Conversations
- [Seamless](https://github.com/facebookresearch/seamless_communication): Speech-to-speech translation (S2ST), Speech-to-text translation (S2TT), Text-to-speech translation (T2ST), Text-to-text translation (T2TT), Automatic speech recognition (ASR)
- [Fairseq(-py)](https://github.com/facebookresearch/fairseq) is a sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling and other text generation tasks.
- [Faiss](https://github.com/facebookresearch/faiss) is a library for efficient similarity search and clustering of dense vectors.
- [PyTorch-BigGraph](https://github.com/facebookresearch/PyTorch-BigGraph) (PBG) is a distributed system for learning graph embeddings for large graphs, particularly big web interaction graphs with up to billions of entities and trillions of edges.
- [Llama 2 Fine-tuning](https://github.com/facebookresearch/llama-recipes) - examples to quickly get started with fine-tuning for domain adaptation and how to run inference for the fine-tuned models. For ease of use, the examples use Hugging Face converted versions of the models.
- [Pearl](https://github.com/facebookresearch/Pearl) - A Production-ready Reinforcement Learning AI Agent Library
- [TorchRecipes](https://github.com/facebookresearch/recipes) - Recipes are a standard, well supported set of blueprints for machine learning engineers to rapidly train models using the latest research techniques without significant engineering overhead.
- [fastText](https://github.com/facebookresearch/fastText) is a library for efficient learning of word representations and sentence classification.
- [ParlAI](https://github.com/facebookresearch/ParlAI) - a framework for training and evaluating AI models on a variety of openly available dialogue datasets.

## [AWS samples](https://github.com/orgs/aws-samples/repositories?q=&type=all&language=python&sort=)

- [Image Generator with Stable Diffusion on Amazon Bedrock using Streamlit](https://github.com/aws-samples/image-generator-with-stable-diffusion-on-amazon-bedrock-using-streamlit) - A quick demostration to deploy a Stable Diffusion Web application with containers running on Amazon ECS. The model is provided by Amazon Bedrock in this example
- [Transactional Data Lake using Apache Iceberg with AWS Glue Streaming and MSK Connect (Debezium)](https://github.com/aws-samples/transactional-datalake-using-amazon-msk-serverless-and-apache-iceberg-on-aws-glue) - Stream CDC into an Amazon S3 data lake in Apache Iceberg format with AWS Glue Streaming using Amazon MSK Serverless and MSK Connect (Debezium)
- [MLOps using Amazon SageMaker and GitHub Actions](https://github.com/aws-samples/mlops-sagemaker-github-actions) - MLOps example using Amazon SageMaker Pipeline and GitHub Actions
- [Near-Real Time Usage Anomaly Detection using OpenSearch](https://github.com/aws-samples/near-realtime-aws-usage-anomaly-detection) - Detect AWS usage anomalies in near-real time using OpenSearch Anomaly Detection and CloudTrail for improved cost management and security
- [Amazon DocumentDB (with MongoDB compatibility) samples](https://github.com/aws-samples/amazon-documentdb-samples) - Code samples that demonstrate how to use Amazon DocumentDB
- [Marketing Content Generator](https://github.com/aws-samples/generative-ai-marketing-portal) - CDK Deployment for a sample marketing portal using generative AI for content generation and distribution; Marketing Content Generation and Distribution powered by Generative AI
- [Amazon SageMaker and AWS Trainium Examples](https://github.com/aws-samples/sagemaker-trainium-examples) - Text classification using Transformers, Pretrain BERT using Wiki Data, Pretrain/Fine tune Llama using Wiki Data.
- [AWS SageMaker Local Mode](https://github.com/aws-samples/amazon-sagemaker-local-mode) - Amazon SageMaker Local Mode Examples
- [End-to-end AIoT w/ SageMaker and Greengrass 2.0 on NVIDIA Jetson Nano](https://github.com/aws-samples/aiot-e2e-sagemaker-greengrass-v2-nvidia-jetson) - Hands-on lab from ML model training to model compilation to edge device model deployment on the AWS Cloud. It covers the detailed method of compiling SageMaker Neo for the target device, including cloud instance and edge device, and how to write and deploy Greengrass-v2 components from scratch.
- [InsuranceLake ETL with CDK Pipeline](https://github.com/aws-samples/aws-insurancelake-etl) - This solution helps you deploy ETL processes and data storage resources to create an Insurance Lake using Amazon S3 buckets for storage, AWS Glue for data transformation, and AWS CDK Pipelines. It is originally based on the AWS blog Deploy data lake ETL jobs using CDK Pipelines, and complements the InsuranceLake Infrastructure project.
- [Amazon Forecast](https://aws.amazon.com/forecast/) - for a low-code/no-code fully managed time series AI/ML forecasting service.
- [AutoGluon](https://github.com/autogluon/autogluon) - if you prefer more control over the forecasting model exploration, training, and evaluation processes.
- [Retrieval Augmented Generation with Streaming LLM](https://github.com/aws-samples/smartsearch-ai-knowledge-workshop) - leverage LLMs for RAG(Retrieval Augmented Generation).
- [Build generative AI agents with Amazon Bedrock, Amazon DynamoDB, Amazon Kendra, Amazon Lex, and LangChain](https://github.com/aws-samples/generative-ai-amazon-bedrock-langchain-agent-example)
  

## [NVIDIA](https://github.com/NVIDIA)

- [Deep Learning Examples](https://github.com/NVIDIA/DeepLearningExamples) - State-of-the-Art Deep Learning scripts organized by models - easy to train and deploy with reproducible accuracy and performance on enterprise-grade infrastructure.
- [NeMo](https://github.com/NVIDIA/NeMo): a toolkit for conversational AI

## Different

### Data Science Resources

- [Data Science Resources - learning](https://github.com/datasciencemasters/go) - The open-source curriculum for learning to be a Data Scientist (quite basic, but nice links to books, etc.)
- [Data Science Resources](https://github.com/academic/awesome-datascience) - An Data Science repository to learn and apply for real world problems.
- [Data Science Cheatsheets](https://github.com/FavioVazquez/ds-cheatsheets) - List of Data Science Cheatsheets to rule the world
- [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook) - full text in Jupyter Notebooks
- [Data science Python notebooks](https://github.com/donnemartin/data-science-ipython-notebooks) - Deep learning (TensorFlow, Theano, Caffe, Keras), scikit-learn, Kaggle, big data (Spark, Hadoop MapReduce, HDFS), matplotlib, pandas, NumPy, SciPy, Python essentials, AWS, and various command lines.
  
### NLP Resources

- [NLP state-of-the-art](https://github.com/sebastianruder/NLP-progress) - Tracking Progress in Natural Language Processing
- [NMT Tutorial](https://github.com/ymoslem/OpenNMT-Tutorial) - Neural Machine Translation (NMT) tutorial. Data preprocessing, model training, evaluation, and deployment.
- [NMT](https://github.com/Prompsit/mutnmt) - An educational tool to train, inspect, evaluate and translate using neural engines
- [NMT Evaluation framework](https://github.com/Optum/nmt) - A useful framework to evaluate and compare different Machine Translation engines between each other on variety datasets.
- [FasterNMT](https://github.com/iC-RnD/FasterNMT) - NMT incl. data preprocessing, model training, evaluation, and deployment with great performance.
- [DeepLearningForNLPInPytorch](https://github.com/rguthrie3/DeepLearningForNLPInPytorch) - an IPython Notebook tutorial on deep learning for natural language processing, including structure prediction.
- [alennlp](https://github.com/allenai/allennlp) - An open-source NLP research library, built on PyTorch.
- [Natural Language Processing Tutorial for Deep Learning Researchers](https://github.com/graykode/nlp-tutorial)
- [Oxford Deep NLP 2017 course](https://github.com/oxford-cs-deepnlp-2017/lectures)
- [awasome-nlp](https://github.com/keon/awesome-nlp) - A curated list of resources dedicated to Natural Language Processing (NLP)
- [German-NLP Datasets](https://github.com/TatjanaChernenko/German-NLP)
- [Speech Cognitive Service](https://github.com/LaloCo/SpeechCognitiveService_Translate) - A Jupyter Notebook that details how to use Azure's Speech Cognitive Service to Translate speech

### ML Resources
- [Applied ML](https://github.com/eugeneyan/applied-ml) - (not really up-to-date, but good) Papers & tech blogs by companies sharing their work on data science & machine learning in production.
- [500 AI projects](https://github.com/ashishpatel26/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code) - 500 AI Machine learning, Deep learning, Computer vision, NLP Projects with code

### Prediction
- [PredictionIO](https://github.com/apache/predictionio) - Apache; a machine learning server for developers and ML engineers.
- [Conforal Prediction Tutorials](https://github.com/valeman/awesome-conformal-prediction) - A professionally curated list of awesome Conformal Prediction videos, tutorials, books, papers, PhD and MSc theses, articles and open-source libraries.
- [Time Series Prediction](https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction) - LSTM Neural Network for Time Series Prediction
- [Stock Prediction Models](https://github.com/huseinzol05/Stock-Prediction-Models) - gathers machine learning and deep learning models for Stock forecasting including trading bots and simulations
- [Lime](https://github.com/marcotcr/lime): Explaining the predictions of any machine learning classifier
- [Time Series Prediction](https://github.com/tgjeon/TensorFlow-Tutorials-for-Time-Series) - TensorFlow Tutorial for Time Series Prediction
